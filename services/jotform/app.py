import gradio as gr
from utils.prompt_constructor import get_prompt_for_image_gen
from utils.local_img_generation import generate_img
from utils.remove_bg import get_bg_removed_img
from io import BytesIO
import PIL.Image

def generate_prompt(image_type, form_id, prompt, llm_model):
    if prompt:
        return prompt, None
    elif form_id:
        try:
            form_id = int(form_id)
            if form_id <= 0:
                raise ValueError("Form ID must be a positive integer.")
            prompt_file_path = f"prompts/{image_type}_img_prompt.txt"
            return get_prompt_for_image_gen(prompt_file_path, form_id, llm_model), None
        except ValueError as ve:
            return None, f"Invalid Form ID for {image_type}: {str(ve)}"
    else:
        return None, "Either prompt or Form ID must be provided."

def generate_image(image_type, img_model, prompt, negative_prompt, **kwargs):
    try:
        image_data = generate_img(img_model, prompt, negative_prompt, **kwargs)
        if image_type == 'avatar':
            image_data = get_bg_removed_img(image_bytes=image_data)

        img = PIL.Image.open(BytesIO(image_data))
        return img, None
    except Exception as e:
        return None, f"Error generating image: {str(e)}"

def create_image_generation_tab(image_type):
    with gr.Tab(f"{image_type.capitalize()} Generation"):
        with gr.Row():
            form_id = gr.Number(value=241773743154055, label="Form ID", precision=0, minimum=1)
            prompt = gr.Textbox(label="Prompt", placeholder="Prompt")
            negative_prompt = gr.Textbox(label="Negative prompt", placeholder="Negative prompt")
        
        with gr.Row():
            llm_model = gr.Dropdown(["gpt-3.5-turbo", "llama3-8b", "llama3-70b", "mixtral-8x7b"], value="gpt-3.5-turbo", label="Prompt Model")
            img_model = gr.Dropdown(
                [
                    "sd_xl_base_1.0",
                    "sd_xl_turbo_1.0_fp16",
                    "Juggernaut_X_RunDiffusion",
                    "Juggernaut_X_RunDiffusion_Hyper",
                    "sd3_medium_incl_clips_t5xxlfp16",
                    "Juggernaut-XL_v9_RunDiffusionPhoto_v2",
                ],
                value="Juggernaut-XL_v9_RunDiffusionPhoto_v2",
                label="Image Model"
            )
        with gr.Accordion("Advanced Options", open=False):
            with gr.Row():
                use_detailed_hands_lora = gr.Checkbox(value=True, label="Detailed Hands Lora")
                use_white_bg_lora = gr.Checkbox(value=False, label="White Background Lora")

            with gr.Row():
                img_width = gr.Dropdown(["512", "832"], value="832", label="Image Width")
                img_height = gr.Dropdown(["512", "1216"], value="1216", label="Image Height")
                sampling_method = gr.Dropdown(
                    ["DPM++ 2M", "DPM++ SDE", "DPM++ 2M SDE", "DPM++ 2M SDE Heun", "DPM++ 2S a",
                    "DPM++ 3M SDE", "Euler a", "Euler", "LMS", "Heun", "DPM2", "DPM2 a", "DPM fast",
                    "DPM adaptive", "Restart", "DDIM", "PLMS", "UniPC", "LCM"],
                    value="DPM++ 2M",
                    label="Sampling method"
                )
                schedule_type = gr.Dropdown(
                    ["Automatic", "Uniform", "Karras", "Exponential", "Poly Exponential", "SGM Uniform"],
                    value="Karras",
                    label="Schedule type"
                )
                batch_count = gr.Slider(minimum=1, maximum=100, value=1, step=1, label="Batch count")
                batch_size = gr.Slider(minimum=1, maximum=8, value=1, step=1, label="Batch size")
                cfg_scale = gr.Slider(minimum=1, maximum=30, value=6, step=0.5, label="CFG Scale")
                seed = gr.Number(value=-1, minimum=-1, label="Seed")
                sampling_steps = gr.Slider(minimum=1, maximum=150, value=25, step=1, label="Sampling steps")
        
        generate_button = gr.Button("Generate Image", size='sm')
        
        output_prompt = gr.Textbox(label="Generated Prompt", placeholder="Prompt generated by LLM", interactive=False)
        output_gallery = gr.Gallery(label="Generated Images", allow_preview=True, elem_id=f"output-gallery-{image_type}", columns=[3], rows=[1], object_fit="contain", height=700)
        error_output = gr.Textbox(label="Error", visible=False)
        
        def _generate_prompt(image_type, form_id, prompt, llm_model):
            generated_prompt, error = generate_prompt(image_type, form_id, prompt, llm_model)
            return generated_prompt, error
        
        def _generate_image(image_type:str, img_model:str, prompt:str, negative_prompt:str, width:int, 
                            height:int, sampling_method:str, schedule_type:str, batch_count:int, batch_size:int, 
                            cfg_scale:float, seed:int, sampling_steps:int):
                parameters = {
                    'width': width,
                    'height': height,
                    'sampling_method': sampling_method,
                    'schedule_type': schedule_type,
                    'batch_count': batch_count,
                    'batch_size': batch_size,
                    'cfg_scale': cfg_scale,
                    'seed': seed,
                    'sampling_steps': sampling_steps,
                    'use_detailed_hands_lora': use_detailed_hands_lora.value,
                    'use_white_bg_lora': use_white_bg_lora.value,
                }
                image, error = generate_image(image_type, img_model, prompt, negative_prompt, **parameters)
                return [image] if image else None, error
        
        generate_button.click(
            _generate_prompt,
            inputs=[gr.Textbox(value=image_type, visible=False), form_id, prompt, llm_model],
            outputs=[output_prompt, error_output]
        ).then(
            _generate_image,
            inputs=[gr.Textbox(value=image_type, visible=False), img_model, output_prompt, negative_prompt,
                    img_width, img_height, sampling_method, schedule_type, batch_count, batch_size,
                    cfg_scale, seed, sampling_steps],
            outputs=[output_gallery, error_output]
        )
css = '''
.gradio-container{max-width: 670px !important}
h1{text-align:center}
.clickable-image img {
    cursor: pointer;
}
'''
with gr.Blocks(css=css, theme="bethecloud/storj_theme") as demo:
    gr.Markdown("# AI Background and Avatar Generator")
    
    create_image_generation_tab("background")
    create_image_generation_tab("avatar")

if __name__ == "__main__":
    demo.launch(server_port=5555)